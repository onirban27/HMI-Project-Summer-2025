@article{Sehrt2024AutoREBA,
title = {Auto-REBA: Improving Postural Ergonomics Using an Automatic Real-Time REBA Score in Virtual Reality},
author = {Jessica Sehrt and Mustafa Rafati and Cynthia Cheema and Daniel Garofano and Dayana Hristova and Elias J\"{a}ger and Valentin Schwind},
url = {https://doi.org/10.4017/gt.2024.23.s.989.opp
https://vali.de/wp-content/uploads/2024/11/Sehrt2024AutoREBA.pdf},
doi = {10.4017/gt.2024.23.s.989.opp},
issn = {1569-1101},
year = {2024},
date = {2024-09-02},
urldate = {2024-09-02},
journal = {Official Journal of the International Society for Gerontechnology},
volume = {23},
issue = {2},
pages = {1-1},
abstract = {This pilot system explores the integration of advanced technologies, including Virtual Reality (VR) and wearable devices, with the REBA (Rapid Entire Body Assessment) (Hignett \& McAtamney, 2000) technique for real-time posture correction and ergonomic assessment. Aimed at mitigating musculoskeletal strain and enhancing ergonomic practices, the research investigates the effectiveness of immediate feedback mechanisms in dynamic and simulated work environments. The ultimate goal is to enable elderly individuals to remain in the workplace longer (Escorpizo, 2008).},
keywords = {},
pubstate = {published},
tppubtype = {article}
}

@article{Lucchetti2025Substance,
	author = {Lucchetti, M. and others},
	title = {{Substance Beats Style: Why Beginning Students Fail to Code with LLMs}},
	journal = {arXiv preprint arXiv:2410.19792},
	year = {2025},
	eprint = {2410.19792},
	archivePrefix = {arXiv},
	primaryClass = {cs.HC},
	doi = {10.48550/arXiv.2410.19792},
	url = {https://doi.org/10.48550/arXiv.2410.19792}
}

@article{Nguyen2024Beginning,
	author = {Nguyen, H. and others},
	title = {{How Beginning Programmers and Code LLMs (Mis)read Each Other}},
	journal = {arXiv preprint arXiv:2401.15232},
	year = {2024},
	eprint = {2401.15232},
	archivePrefix = {arXiv},
	primaryClass = {cs.HC},
	doi = {10.48550/arXiv.2401.15232},
	url = {https://doi.org/10.48550/arXiv.2401.15232}
}

@article{Chen2023Unleashing,
	author = {Chen, Bairu and Zhang, Zhen and Langren√©, Nicolas and Zhu, Shengyao},
	title = {{Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review}},
	journal = {arXiv preprint arXiv:2310.14735},
	year = {2023},
	eprint = {2310.14735},
	archivePrefix = {arXiv},
	doi = {10.48550/arXiv.2310.14735},
	url = {https://doi.org/10.48550/arXiv.2310.14735}
}

@article{Ramnath2025Systematic,
	author = {Ramnath, Kiran and Zhou, Kailong and Guan, Shiyue and Mishra, Saurabh Srivastava and Qi, Xinyu and Shen, Zhiqi and others},
	title = {{A Systematic Survey of Automatic Prompt Optimization Techniques}},
	journal = {arXiv preprint arXiv:2502.16923},
	year = {2025},
	eprint = {2502.16923},
	archivePrefix = {arXiv},
	doi = {10.48550/arXiv.2502.16923},
	url = {https://doi.org/10.48550/arXiv.2502.16923}
}

@article{Lucchetti2024Beginning,
	author = {Lucchetti, Nicholas and Gupta, Vaibhav and Weimer, Westley},
	title = {{Why Beginning Students Struggle with Large Language Models (and How to Help)}},
	journal = {arXiv preprint arXiv:2410.19792},
	year = {2024},
	eprint = {2410.19792},
	archivePrefix = {arXiv},
	doi = {10.48550/arXiv.2410.19792},
	url = {https://doi.org/10.48550/arXiv.2410.19792}
}

@article{Yang2025Underspecified,
	author = {Yang, Jianyu and Mou, Chenghao and Neubig, Graham},
	title = {{Underspecified Prompts in Large Language Models: Problems, Challenges, and Opportunities}},
	journal = {arXiv preprint arXiv:2505.13360},
	year = {2025},
	eprint = {2505.13360},
	archivePrefix = {arXiv},
	doi = {10.48550/arXiv.2505.13360},
	url = {https://doi.org/10.48550/arXiv.2505.13360}
}

@article{Knoth2024AI,
	author = {Knoth, Petr and Tennant, Jon and Lee, Mark R. and Rehak, Martin},
	title = {{AI Literacy and Its Implications for Prompt Engineering Strategies}},
	journal = {Computers and Education: Artificial Intelligence},
	volume = {5},
	pages = {100225},
	year = {2024},
	doi = {10.1016/j.caeai.2024.100225},
	url = {https://doi.org/10.1016/j.caeai.2024.100225}
}

@article{Mao2025Prompts,
	author = {Mao, Yuetian and Naous, Tarek and Li, Haizhi and Gao, Qingyi and Yu, James and Ji, Heng and McAuley, Julian},
	title = {{From Prompts to Templates: A Systematic Prompt Template Analysis for Real-world LLMapps}},
	journal = {arXiv preprint arXiv:2504.02052},
	year = {2025},
	eprint = {2504.02052},
	archivePrefix = {arXiv},
	doi = {10.48550/arXiv.2504.02052},
	url = {https://doi.org/10.48550/arXiv.2504.02052}
}

@article{Khurana2024Why,
	author = {Khurana, Udit and Park, Joon Sung and Bernstein, Michael S. and Liang, Percy},
	title = {{Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions}},
	journal = {arXiv preprint arXiv:2402.08030},
	year = {2024},
	eprint = {2402.08030},
	archivePrefix = {arXiv},
	doi = {10.48550/arXiv.2402.08030},
	url = {https://doi.org/10.48550/arXiv.2402.08030}
}

@article{Yang2022Re3,
	author = {Yang, Kevin and Peng, Nanyun and Klein, Dan},
	title = {{Re3: Recursive Reprompting and Revision for Story Generation}},
	journal = {arXiv preprint arXiv:2209.12099},
	year = {2022},
	eprint = {2209.12099},
	archivePrefix = {arXiv},
	doi = {10.48550/arXiv.2209.12099},
	url = {https://doi.org/10.48550/arXiv.2209.12099}
}

@inproceedings{Saxena2024Prompt,
	author = {Saxena, Vishwas and others},
	title = {{Prompt Engineering for Software Engineering Tasks: A Comparative Study of 14 Prompting Techniques}},
	booktitle = {Proceedings of the ACM/IEEE 46th International Conference on Software Engineering (ICSE 2024)},
	publisher = {ACM},
	address = {New York, NY, USA},
	year = {2024},
	doi = {10.1145/3640543.3645200},
	url = {https://doi.org/10.1145/3640543.3645200}
}

@article{Webson2025From,
	author = {Webson, Albert and others},
	title = {{From Prompt Engineering to Prompt Science: Principles and Practices}},
	journal = {arXiv preprint arXiv:2502.04295},
	year = {2025},
	eprint = {2502.04295},
	archivePrefix = {arXiv},
	doi = {10.48550/arXiv.2502.04295},
	url = {https://doi.org/10.48550/arXiv.2502.04295}
}

@article{In2024Alternatives,
	author = {In, J. and Kim, S. and Lee, J.},
	title = {{Alternatives to the P Value: Connotations of Significance}},
	journal = {Korean Journal of Anesthesiology},
	volume = {77},
	number = {3},
	pages = {195--204},
	year = {2024},
	doi = {10.4097/kja.24199},
	url = {https://doi.org/10.4097/kja.24199}
}

@article{Tomczak2022Need,
	author = {Tomczak, M. and Tomczak, E.},
	title = {{The Need to Report Effect Size in Statistical Analyses: Kendall's W and Beyond}},
	journal = {Trends in Psychology},
	volume = {30},
	number = {2},
	pages = {159--173},
	year = {2022},
	doi = {10.1007/s43076-021-00120-0},
	url = {https://doi.org/10.1007/s43076-021-00120-0}
}

@article{Benavoli2016Should,
	author = {Benavoli, A. and Corani, G. and Mangili, F.},
	title = {{Should we really use post-hoc tests based on mean-ranks?}},
	journal = {The Journal of Machine Learning Research},
	volume = {17},
	number = {1},
	pages = {152--161},
	year = {2016}
}

@article{Xiang2022Large,
	author = {Xiang, Y. and Chen, C. and Zhang, J.},
	title = {{Large-Sample Properties of the Wilcoxon Signed-Rank Test under Dependence}},
	journal = {Journal of Statistical Computation and Simulation},
	volume = {92},
	number = {7},
	pages = {1465--1480},
	year = {2022},
	doi = {10.1080/00949655.2021.1963745},
	url = {https://doi.org/10.1080/00949655.2021.1963745}
}

@article{Armstrong2021When,
	author = {Armstrong, R. A.},
	title = {{When to Use the Bonferroni Correction}},
	journal = {Ophthalmic and Physiological Optics},
	volume = {41},
	number = {2},
	pages = {227--234},
	year = {2021},
	doi = {10.1111/opo.12686},
	url = {https://doi.org/10.1111/opo.12686}
}

@article{Tyagi2022Use,
	author = {Tyagi, A. and Salhotra, R. and Agrawal, A. and Vashist, I. and Malhotra, R. K.},
	title = {{Use of Pearson and Spearman correlation testing in Indian anesthesia journals: An audit}},
	journal = {J. Anaesthesiol. Clin. Pharmacol.},
	volume = {39},
	number = {4},
	pages = {550--556},
	year = {2022},
	doi = {10.4103/joacp.joacp_13_22}
}

@article{Winter2024Comparing,
	author = {de Winter, J. C. F. and Gosling, S. D. and Potter, J.},
	title = {{Comparing the Pearson and Spearman Correlation Coefficients Across Distributions and Sample Sizes}},
	journal = {arXiv preprint arXiv:2408.15979},
	year = {2024},
	eprint = {2408.15979},
	archivePrefix = {arXiv}
}

@article{Upadhyay2021Correlation,
	author = {Upadhyay, A. K. and Shukla, S.},
	title = {{Correlation study to identify the factors affecting COVID-19 case fatality rates in India}},
	journal = {Nonlinear Dynamics},
	year = {2021},
	note = {Supplementary appendix includes Spearman's rank formula},
	pmcid = {PMC8110283}
}

@article{Gu2022Complex,
	author = {Gu, Z.},
	title = {{Complex heatmap visualization}},
	journal = {iMeta},
	volume = {1},
	number = {3},
	pages = {e43},
	year = {2022},
	doi = {10.1002/imt2.43}
}

@article{Briganti2024Network,
	author = {Briganti, G. and others},
	title = {{Network analysis: An overview for mental health research}},
	journal = {Front. Psychiatry},
	year = {2024},
	pmcid = {PMC11564129}
}

@article{Sweller1988Cognitive,
	author = {Sweller, J.},
	title = {{Cognitive load during problem solving}},
	journal = {Cognitive Science},
	volume = {12},
	number = {2},
	pages = {257--285},
	year = {1988},
	note = {Foundational cognitive load theory}
}

@inproceedings{Wu2022AI,
	author = {Wu, T. and Terry, M. and Cai, C. J.},
	title = {{AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts}},
	booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
	year = {2022},
	doi = {10.1145/3491102.3517582},
	url = {https://doi.org/10.1145/3491102.3517582}
}

@article{Hattie2007Power,
	author = {Hattie, J. and Timperley, H.},
	title = {{The power of feedback}},
	journal = {Review of Educational Research},
	volume = {77},
	number = {1},
	pages = {81--112},
	year = {2007},
	doi = {10.3102/003465430298487},
	url = {https://doi.org/10.3102/003465430298487},
	note = {Meta-analysis showing effect sizes d=0.48-0.79}
}

@article{Madaan2023Self,
	author = {Madaan, A. and others},
	title = {{Self-Refine: Iterative Refinement with Self-Feedback}},
	journal = {arXiv preprint arXiv:2303.17651},
	year = {2023},
	eprint = {2303.17651},
	archivePrefix = {arXiv},
	url = {https://arxiv.org/abs/2303.17651},
	note = {~20\% improvement through iterative refinement}
}

@inproceedings{Min2022Rethinking,
	author = {Min, S. and others},
	title = {{Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?}},
	booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
	year = {2022},
	eprint = {2202.12837},
	archivePrefix = {arXiv},
	url = {https://arxiv.org/abs/2202.12837}
}

@inproceedings{Liu2022What,
	author = {Liu, J. and others},
	title = {{What Makes Good In-Context Examples for GPT-3?}},
	booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
	year = {2022},
	url = {https://aclanthology.org/2022.deelio-1.10/}
}

@article{Arawjo2023ChainForge,
	author = {Arawjo, I. and others},
	title = {{ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing}},
	journal = {arXiv preprint arXiv:2309.09128},
	year = {2023},
	eprint = {2309.09128},
	archivePrefix = {arXiv},
	url = {https://arxiv.org/abs/2309.09128}
}